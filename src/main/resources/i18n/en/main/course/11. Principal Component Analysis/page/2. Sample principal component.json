{
  "meta.title": "Sample Principal Component",
  "intro.title": "Sample Principal Components",

  "section.1.title": "Sample Principal Components",
  "section.1.text1": "Let $S$ be the sample covariance matrix:",
  "section.1.eq1": "$$S = \\frac{1}{n-1} \\sum_{i=1}^{n} (\\mathbf{X}_i - \\bar{\\mathbf{X}})(\\mathbf{X}_i - \\bar{\\mathbf{X}})^{\\top},$$",
  "section.1.text2": "and let $l_1 > \\cdots > l_p$ be the latent roots of $S$. The latent roots are distinct with probability one. Let $H$ be a $p \\times p$ orthogonal matrix such that",
  "section.1.eq2": "$$H^{\\top} S H = \\mathrm{diag}(l_1, \\ldots, l_p).$$",

  "section.2.title": "Maximum Likelihood Estimation of Principal Components",
  "section.2.text1": "The components $\\hat{\\mathbf{q}}_i := H^{\\top} \\mathbf{X}$ are called the $i$th sample principal components.",
  "section.2.theorem.title": "",
  "section.2.theorem.text1": "Suppose $\\mathbf{X}$ is distributed as a multivariate normal distribution $\\mathcal{N}(0, \\Sigma)$, where $\\Sigma$ has latent roots $\\lambda_1, \\ldots, \\lambda_r$ with multiplicities $m_1, \\ldots, m_r$, respectively. The maximum likelihood estimator of $\\lambda_i$ is given by",
  "section.2.theorem.eq1": "$$\\hat{\\lambda}_i = \\frac{1}{m_i}\\frac{n-1}{n} \\sum_{j \\in L_i} l_j, \\quad i = 1, \\ldots, r,$$",
  "section.2.theorem.text2": "where $L_i$ is the set of indices $m_1 + \\cdots + m_{i-1} + 1, \\ldots, m_1 + \\cdots + m_i$, and the maximum likelihood estimator of $\\mathbf{q}_j$ is $\\hat{\\mathbf{q}}_j = H_i P_{ij}$, where $P_{ij}$ is any orthogonal matrix such that the first element in each column of $\\hat{\\mathbf{q}}_j$ is nonnegative.",

  "section.3.title": "Asymptotic Distribution of Sample Principal Components",
  "section.3.theorem.title": "",
  "section.3.theorem.text1": "Let $\\lambda_1, \\ldots, \\lambda_p$ be distinct roots, and $\\mathbf{q}_1, \\ldots, \\mathbf{q}_p$ be the corresponding eigenvectors. Then it holds that",
  "section.3.theorem.eq1": "$$\\sqrt{n}(\\hat{\\mathbf{q}}_i - \\mathbf{q}_i) \\xrightarrow{d} \\mathcal{N}(0, \\Sigma_q),$$",
  "section.3.theorem.text2": "where",
  "section.3.theorem.eq2": "$$\\Sigma_q = \\sum_{j \\neq i} \\frac{\\lambda_i \\lambda_j}{(\\lambda_i - \\lambda_j)^2} \\mathbf{q}_j \\mathbf{q}_j^{\\top}.$$",
  "section.3.theorem.text3": "In addition, $\\hat{\\mathbf{q}}_i$ is asymptotically independent of $l_i$.",

  "section.4.title": "Numerical Examples",
  "section.4.sub1": "Numerical Examples (I): Library Preparation",
  "section.4.desc1": "We begin by loading the necessary R packages for multivariate analysis and visualization.",
  "section.4.code1": "library(MVT)\n## Loading required package: fastmatrix\n\nlibrary(ggcorrplot)\n## Loading required package: ggplot2\n\nlibrary(ggfortify)\nlibrary(elasticnet)\n## Loading required package: lars\n## Loaded lars 1.3",

  "section.4.sub2": "Numerical Examples (II): Sample Covariance Matrix",
  "section.4.desc2": "We compute the sample covariance matrix of exam scores to observe relationships among variables.",
  "section.4.code2": "cov(examScor)\n##              mechanics   vectors   algebra   analysis statistics\n## mechanics     305.7680   127.22257 101.57941 106.27273 117.40491\n## vectors       127.2226   172.84222  85.15726  94.67294  99.01202\n## algebra       101.5794    85.15726 112.88597 112.11338 121.87056\n## analysis      106.2727    94.67294 112.11338 220.38036 155.53553\n## statistics    117.4049    99.01202 121.87056 155.53553 297.75536",

  "section.4.sub3": "Numerical Examples (III): Sample Correlation Matrix",
  "section.4.desc3": "To eliminate the influence of variable scales, we compute the sample correlation matrix. This standardization allows us to focus purely on dependency structure.",
  "section.4.code3": "examScor_cr = cor(examScor)\nexamScor_cr\n##              mechanics   vectors   algebra   analysis statistics\n## mechanics     1.0000000  0.5534052  0.5467511  0.4093920  0.3890993\n## vectors       0.5534052  1.0000000  0.6096447  0.4850813  0.4364487\n## algebra       0.5467511  0.6096447  1.0000000  0.7108059  0.6647357\n## analysis      0.4093920  0.4850813  0.7108059  1.0000000  0.6071743\n## statistics    0.3890993  0.4364487  0.6647357  0.6071743  1.0000000"
}
