{
  "meta.title": "UMVUE and Rao–Blackwell Theorem",
  "intro.title": "UMVUE and Rao–Blackwell Theorem",
  "intro.lead": "We introduce the concept of the uniformly minimum variance unbiased estimator (UMVUE), the Rao–Blackwell theorem, and the Lehmann–Scheffé theorem that guarantees uniqueness of UMVUE.",

  "sec.umvue.title": "Uniformly Minimum Variance Unbiased Estimator",
  "sec.umvue.caption": "Uniformly minimum variance unbiased estimator",
  "sec.umvue.text1": "An unbiased estimator $T(X)$ of $q(\\theta)$ is called the uniformly minimum variance unbiased estimator (UMVUE) if for any other unbiased estimator $U(X)$, the following holds:",
  "sec.umvue.eq1": "$$\\operatorname{Var}_\\theta[T(X)] \\le \\operatorname{Var}_\\theta[U(X)].$$",

  "sec.rb.title": "Rao–Blackwell Theorem",
  "sec.rb.caption": "Rao–Blackwell theorem",
  "sec.rb.text1": "Let $T = T(X)$ be a sufficient statistic and $\\hat{\\theta}(X)$ be an arbitrary unbiased estimator of $\\theta$. Define",
  "sec.rb.eq1": "$$\\tilde{\\theta}(X) = \\mathbb{E}_\\theta[\\hat{\\theta}(X)\\mid T].$$",
  "sec.rb.text2": "Then we have the following results:",
  "sec.rb.item1": "$\\tilde{\\theta}(X)$ is also an unbiased estimator of $\\theta$.",
  "sec.rb.item2": "For any $\\theta \\in \\Theta$, we have",
  "sec.rb.eq2": "$$\\operatorname{Var}_\\theta[\\tilde{\\theta}(X)] \\le \\operatorname{Var}_\\theta[\\hat{\\theta}(X)].$$",

  "sec.proof1.title": "Proof (i)",
  "sec.proof1.caption": "Proof of unbiasedness",
  "sec.proof1.text1": "We first verify that the Rao–Blackwellized estimator is unbiased:",
  "sec.proof1.eq1": "$$\\mathbb{E}_\\theta[\\hat{\\theta}(X)] = \\theta.$$",
  "sec.proof1.eq2": "$$\\mathbb{E}[\\tilde{\\theta}(X)] = \\mathbb{E}\\big[\\mathbb{E}_\\theta[\\hat{\\theta}(X)\\mid T]\\big].$$",
  "sec.proof1.eq3": "$$= \\mathbb{E}_\\theta[\\hat{\\theta}(X)].$$",
  "sec.proof1.eq4": "$$= \\theta.$$",
  "sec.proof1.text2": "Hence, $\\tilde{\\theta}(X)$ is also an unbiased estimator of $\\theta$.",

  "sec.proof2.title": "Proof (ii)",
  "sec.proof2.caption": "Proof of variance reduction",
  "sec.proof2.text1": "Next, we show that the Rao–Blackwellized estimator has no larger variance:",
  "sec.proof2.eq1": "$$\\operatorname{Var}_\\theta(\\hat{\\theta}) = \\mathbb{E}_\\theta[(\\hat{\\theta}-\\theta)^2].$$",
  "sec.proof2.eq2": "$$= \\mathbb{E}_\\theta[(\\hat{\\theta}-\\tilde{\\theta} + \\tilde{\\theta}-\\theta)^2]$$",
  "sec.proof2.eq3": "$$= \\mathbb{E}_\\theta[(\\tilde{\\theta}-\\theta)^2] + \\mathbb{E}_\\theta[(\\hat{\\theta}-\\tilde{\\theta})^2] + 2\\mathbb{E}_\\theta[(\\tilde{\\theta}-\\theta)(\\hat{\\theta}-\\tilde{\\theta})].$$",
  "sec.proof2.eq4": "$$\\mathbb{E}_\\theta[(\\tilde{\\theta}-\\theta)(\\hat{\\theta}-\\tilde{\\theta})] = \\mathbb{E}_\\theta\\big[\\mathbb{E}_\\theta[(\\tilde{\\theta}-\\theta)(\\hat{\\theta}-\\tilde{\\theta})\\mid T]\\big] = 0,$$",
  "sec.proof2.eq5": "since $\\mathbb{E}_\\theta[(\\hat{\\theta}-\\tilde{\\theta})\\mid T]=0$ almost surely.",
  "sec.proof2.eq6": "$$\\Rightarrow \\operatorname{Var}_\\theta(\\hat{\\theta}) = \\operatorname{Var}_\\theta(\\tilde{\\theta}) + \\mathbb{E}_\\theta[(\\hat{\\theta}-\\tilde{\\theta})^2] \\ge \\operatorname{Var}_\\theta(\\tilde{\\theta}).$$",
  "sec.proof2.text2": "Thus, $\\tilde{\\theta}$ has the minimum variance among all unbiased estimators obtained via Rao–Blackwellization.",


  "sec.ls.title": "Lehmann–Scheffé Theorem",
  "sec.ls.caption": "Lehmann–Scheffé theorem",
  "sec.ls.text1": "Suppose there exists a sufficient and complete statistic $T(X)$. If $q(\\theta)$ is unbiasedly estimable, i.e., there exists an unbiased estimator $\\hat{\\theta}$, then",
  "sec.ls.eq1": "$$\\tilde{\\theta} = \\mathbb{E}_\\theta[\\hat{\\theta}\\mid T],$$",
  "sec.ls.text2": "is also an unbiased estimator. Furthermore, $\\tilde{\\theta}$ is the unique UMVUE of $q(\\theta)$.",

  "sec.lsproof.title": "Proof",
  "sec.lsproof.caption": "Proof of the Lehmann–Scheffé theorem",
  "sec.lsproof.text1": "The key idea is the uniqueness of the UMVUE ensured by the completeness of the sufficient statistic.",
  "sec.lsproof.eq1": "Let $u(X)$ be any unbiased estimator of $q(\\theta)$. Define the Rao–Blackwellized version $$\\tilde{u}(T) = \\mathbb{E}_\\theta[u(X)\\mid T].$$",
  "sec.lsproof.text2": "By the Rao–Blackwell theorem, $\\tilde{u}(T)$ is also an unbiased estimator of $q(\\theta)$, and any such estimator can be written as a measurable function of $T$.",
  "sec.lsproof.eq2": "Let $\\tilde{\\theta}$ be the Lehmann–Scheffé estimator defined as $$\\tilde{\\theta} = \\mathbb{E}_\\theta[\\hat{\\theta}\\mid T].$$",
  "sec.lsproof.text3": "Consider the difference between two unbiased estimators, both expressed as functions of $T$:",
  "sec.lsproof.eq3": "$$\\mathbb{E}_\\theta[\\tilde{\\theta} - \\tilde{u}(T)] = 0 \\quad \\text{for all } \\theta.$$",
  "sec.lsproof.eq4": "Since $T$ is a complete statistic, the only function $g(T)$ satisfying $\\mathbb{E}_\\theta[g(T)] = 0$ for all $\\theta$ is $g(T) = 0$ almost surely. Hence, $$\\tilde{\\theta} = \\tilde{u}(T) \\text{ a.s.}$$",
  "sec.lsproof.text4": "Therefore, $\\tilde{\\theta}$ is not only unbiased but also unique among all unbiased estimators that are functions of $T$. This proves that $\\tilde{\\theta}$ is the unique UMVUE of $q(\\theta)$."
}
